---
title: "R Notebook"
output: html_notebook
---

```{r}
df <- read.csv('../data/restaurants_train.csv')
head(df,5)
```

```{r}
str(df)
```

```{r}
print('Count of missing NAs')
sapply(df, function(x) sum(is.na(x)))
```

## Using PCA on high-dimensional data

Given the data set we have, we have a large number of features and we want to apply an unsupervised method to determine insights. PCA simplifies the features into fewer components to help us visualize hidden patterns in our data.

Identifying if the data is spherical?

```{r}
corrMatrix <- cor(df)
psych::cortest.bartlett(corrMatrix)
```

Since p-value \< 0.05, we reject the $$H_0$$ that the data is spherical.

```{r}
# install.packages('reshape','psych','factoextra')
library(factoextra)
library(psych)
library(reshape)
library(ggplot2)
library(dplyr)
library(tidyr)
library(reshape)

```

```{r}
# Applying PCA
df_scaled <- scale(df)
df_scaled <- df_scaled[,!(colnames(df_scaled) %in% c("income","star_ratings"))]
df_pca <- prcomp(df_scaled)
summary(df_pca)
```

As observed, we have a large number of PCA components that have been generated from the data. Our next step is to determine what PCA component's explains most of the variance of our data.

```{r}
# PCA Variance ratio
pca_summary <- summary(df_pca)
cumulative_varprop <- pca_summary$importance["Cumulative Proportion",]
# Visual
barplot(cumulative_varprop)
abline(h=0.80, col = 'red', lty = 2)
title(main = "PCA explained variance ratio",
      xlab = "PCA components", ylab = "Variance Ratio")
```

As observed, we generated 32 PCA components and 85% of the variance by PCA1 - PCA9. Since a large portion of our variance is observed in these components, we can now reduce the components into 9 and perform some analysis. It will be hard to include all the components since some of the them have low explained variance specially on the right most PCA's which may not be that significant.

```{r}
# PCA Loadings
pca_loadings <- data.frame(features=row.names(df_pca$rotation),df_pca$rotation) 

pca_reduced <- 
  melt(pca_loadings,id=c("features")) %>%
    filter(variable %in% paste0('PC',1:8)) %>%
    group_by(variable) %>%
    top_n(5,abs(value)) %>% 
    ungroup() %>%
    mutate(sign = ifelse(value>0, "+", "-"))


pca_reduced[pca_reduced$variable %in% c("PC1","PC2","PC3","PC4"),] %>%
  ggplot(aes(x=abs(value),y=features,fill=sign)) + 
  geom_bar(stat='identity') +
  facet_wrap(~variable, scales='free_y') +
  theme_classic() +
  labs(x=NULL)

```

```{r}
pca_reduced[pca_reduced$variable %in% c("PC5","PC6","PC7","PC8"),] %>%
  ggplot(aes(x=abs(value),y=features,fill=sign)) + 
  geom_bar(stat='identity') +
  facet_wrap(~variable, scales='free_y') +
  theme_classic() +
  labs(x=NULL)
```

Results:

-   PCA1 - In contrast of $$ low $$ values of social media engagement and advertising to high unemployment rate, economic rate, and average income.

-   PCA2 - $$ low $$ values of features related to holistic employment growth and competitor factors.

-   PCA3 - $$ high $$ values of features related to employee growth and weather conditions.

-   PCA4 - $$ high $$ values of features related to competitor factors and weather conditions.

-   PCA5 - In contrast of $$ high $$ values for inventory turnover, staff turn over and order processing time to $$ low $$ values of restaurant's value for money and promos.

-   PCA6 - $$ high $$ values for variety of products (ie. vegetarian) and accessibility.

-   PCA7 - In contrast of $$low$$ values for unemployment & economic growth rate, and average income to variety of products including seasonality.

-   PCA8 - In contrast of $$ low $$ values of variety of products together with seasonal promos to $$high$$ employee satisfactory performance/growth.

## Clustering reduced data

Using PCA to reduced the dimensionality and determine importance of features in generated Principal Components, we can now try to use this in clustering. Using clustering in reduced dimensions may give us another insights on how these PC's relate.

```{r}
reduced_col <- c("PC1","PC2","PC3","PC4","PC5","PC6","PC7","PC8")
pca_components <- df_pca[['x']][,colnames(df_pca[['x']]) %in% reduced_col]
kmcluster <- kmeans(pca_components,
                    centers = 5, nstart =25)
fviz_cluster(kmcluster,pca_components[])

```

As observed, distinct clusters can't be visualized according to the visualization shown above.
